\chapter{Part IV: Column Operations}
\label{chap:operations}

\afigure{img/memory-performance-graph}{As memory footprint goes down, operation time increases.}{fig:memory-performance-graph}{0.6} 
So far, we have seen that our implementation has given drastical reduction in memory usage and load time. In general, reduced memory usage normally results in higher program performance. However, we have not yet utilized our new column structure. In Figure \ref{fig:memory-performance-graph}, we see that both lookup index generation and source measure lookup operations has been severly slowed down, with the latter has been slowed down with one order of magnitude.

In this chapter, we implement these operations within the columns to use the potential in the storage format and to avoid creation and deletion of \cn{GValue}s in tight loops. We also create and study the performance impact filtering and index creation mechanisms within the columns.

\clearpage

\section{Source Measure Lookup}
\label{sec:Source Measure Lookup}
As we read in Appendix \ref{app:benchmarks}, the source measure lookup operation creates an array of double precision floating point values for a column in a data source. It uses such array as a basic unit for calculations and aggregations within \gd. For simplicity reasons, all numeric types that works as measures in a data mart is converted to 64-bit floating point numbers, even 32-bit integers. Our observation is that we already have these arrays available within the \cn{RealFieldValueCollection}, and that there is no longer need for using the column \fn{Get} function to access values one by one.
%The \bd~functionality in \gap~works strictly on arrays of floating point values (\cn{TArray<double>}). This buffer is created with a \cn{SourceMeasureProvider} class which is linked to a data descriptor. For every composition object in the data source, it calls the \fn{GetValue} method, which returns a \cn{GValue}. The buffer is then filled by calling \fn{GetAsFloat} on all values. 

\begin{delphicode}{Getting an array of doubles using pointer exposure.}{lst:get-double-array}
function RealFieldValueCollection.GetDoubleArray
: TArray<double> ;
begin
  Result := values;
end;
\end{delphicode}
We implement a new function, \fn{GetDoubleArray} in \cn{FieldValueCollection}. This function will, for all supported column types, return a \delphi~array of \cn{double}. If the operation is not supported by a column, \texttt{nil} is returned. For a \cn{RealFieldValueCollection}, it is only a matter of returning a pointer to its internal value buffer.  This is seen in Listing \ref{lst:get-double-array}.
\begin{delphicode}{Getting an array of doubles using creation.}{lst:get-double-array-create}
function IntegerDictionaryFieldValueCollection.GetDoubleArray
: TArray<double>;
begin
  SetLength(Result, maxDatasourceIndex + 1);
  for i := 0 to maxDatasourceIndex do
    Result[i] := dictionary[values[i]];
end;
\end{delphicode}
However, since this operation is also called on integer columns, we see the potential of creating the array within the column anyway, such that the column structure can be utilized. We, therefore, implement this operation for other applicable columns, including dictionary encoded columns. The implementation is seen in Listing \ref{lst:get-double-array-create}.
%As seen in Table X, there are drastic differences between native floating point columns and everything else. For instance, the quantity-column, which is an integer, it takes \~ 1500ms to create a source measure index. The same is the case for tax, which is floating point but dictionary encoded. We hypothetize that the reason for this is the large amount of memory allocations for \cn{GValue}s and access patterns, and that we can do better by operating on the whole column in a batch.

\section{Lookup Index Generation}
\label{sec:Lookup Index Generation}
A common operation in \bd~is to create a lookup index from one table to another, which maps datasource indexes from one datasource to another. The operation is considered as a join operation. In the realm of database technology, such join function takes two columns as input and outputs a mapping from one table to another. There are several algorithms for joining, however the \pn{nested loop} one is the most popular. This algorithm creates a lookup from values to datasoruce indexes for the smalles column, and then scans the largest column by probing the lookup.  

\gd~uses such lookup index to join tables within a data mart, but creating such index is inefficient with the current implementation. We observe that this operation can benefit from the column structure, and avoiding the uneccessesary middle step of creating \cn{GValue}s. Although such operation normally requires two columns as input, \gap~already has a structure, \textit{identifier index}, available for us to use, a structure used several places in the platform \todo{Where?}. The structure is created on demand, and might already exist when needed.

\begin{delphicode}{\fn{GetLookupIndex} implementation}{lst:get-lookup-index}
function ObjectHandleFieldValueCollection.GetLookupIndex
( identifierIndex : TDictionary<string, CompositionObject>)
: TArray<integer>;
begin
  SetLength(Result, maxDatasourceIndex + 1);
  for i := 0 to maxDatasourceIndex do
  begin
    if identifierIndex.TryGetValue(values[i], comObj) then
      Result[i] := comObj.DatasourceIndex
    else
      Result[i] := -1;
  end;
end;
\end{delphicode}
We proceed to implement \cn{GetLookupIndex} in \cn{FieldValueCollection}, which accepts the the identifier index as input and outputs a \cn{TArray<integer>} that maps datasource indexes from the current column to the other. The implementation is seen in Listing \ref{lst:get-lookup-index}.  

\section{Identifier Index}
\label{sec:Identifier Index}
We read about the \textit{identifier index} structure in the previous section, and how it was used in the \fn{GetLookupIndex} operation. This structure maps an identifier, typically a database primary key, to composition objects, and is used to... \todo{Hvor?}. Whenever needed, the structure is created within a datasource on-demand. We believe this operation can benefit from column storage.

\begin{delphicode}{Creating an identifier index in a primitive column}{lst:create-identifier-index}
function PrimitiveFieldValueCollection<TType>.GetIdentifierIndex
( compositionObjects : CompositionObjectCollection )
: TDictionary<string, CompositionObject>;
begin
  Result := TDictionary<string, CCompositionObject>.Create;
  for comObj in compositionObjects do
  begin
    id := valueHelper.ValueToString(values[comObj.DatasourceIndex]);
    Result.Add(id, comObj);
  end;
end;
\end{delphicode}
We implement an operation named \cn{GetIdentifierIndex} in \fn{PrimitiveFieldValueCollection}. This iterates a list of composition objects, looks up the column value based on the datasource index. All identifiers in \gap~are strings, which means that the value helper class must convert the column contents to string before using it as a key in the dictionary. Most objects come in ordered by their datasource index, which means cache locality is maximized.

The \cn{GetIdentifierIndex} is not implemented in the dictionary encoded columns because it is not needed: If a column works as an identifier column, or a primary key, there will only be unique values, which means such column will never benefit from a dictionary.

\section{Predicate Evaluation}
\label{sec:Predicate Evaluation}
One common operation in \gap~is to move certain objects from one datasource to another based on a filter. This is used in actions. We believe the column structure can help this operation by avoiding unecessary memory allocations and layers of indirection. The filters used in such operation are composed by one or more predicates, which can compare values with equal, not equal, greater than, less than, and other comparisons operators. 

% CONSIDER EXPLAINING THIS
%Inspired to look into other places in \gap~to utilize our new storage structure, we look at the filter mechanisms in the task execution unit. One common operation is to add objects to a data source and then do something with a subset of these. This subset is defined by a filter. Previously, the entire data source was enumerated and each object was compared. For each object.
%\begin{enumerate}
    %\item The \cn{GValue} for the Data Descriptor is fetched. Depending on the implementation, this is either a search through pointers or a memory allocation.
    %\item The \cn{GValue} is compared using the comparison methods in the class.
    %\item This is repeated for every predicated that is evaluated. \todo{Figure out what happened on different predicates}
%\end{enumerate}

\begin{delphicode}{Creating a bitmap for the Equal operator.}{lst:create-equal-bitmap}
function PrimitiveFieldValueCollection<TType>.GetEqualBitmap
( value : CGValue )
: BasicBitArray;
begin
  Result := BasicBitArray.Create(maxDatasourceIndex + 1);
  nativeValue := valueHelper.ExtractValue(value);
  for i := 0 to maxDatasourceIndex do
    Result[i] := valueHelper.ValueEqual(values[i], nativeValue);
end;
\end{delphicode}

We introduce a new column operator, \fn{GetBitmap}, that takes an operator and a value as input, and returns a bitmap of matching rows. An implementation of the equal operator is shown in Listing \ref{lst:create-equal-bitmap}. The bitmaps can then be combined efficiently using \texttt{AND} and \texttt{OR} operations, much like bitmap indexes depicted in Figure \ref{fig:bitmap-query}.

In Listing \ref{lst:create-equal-bitmap}, we see the implementation in the generic \cn{PrimitiveFieldValueCollection} class, which means the value helper class must be used to evaluate the predicate. This causes extra overhead in calling the \fn{ValueEqual} function. To avoid this, column operations can be implemented in the sub-classes, such that the delphi value comparison operator can be used.

\section{Test Results}
\label{sec:Test Results}
To test source measure lookup and lookup index operations, Benchmark \ref{bm:q1} was used. In addition to this, Benchmark \ref{bm:odin-load} was used to test identifier index generation, and Benchmark \ref{bm:filter} was used to test predicate evaluation.

\subsection{Source Measure Lookup}
\label{sub:Source Measure Lookup}
\begin{table}
    \centering
    \begin{tabularx}{\textwidth}{X | X X X X}
        SF0.01 & \texttt{QUANTITY} & \texttt{EXTENDEDPRICE} & \texttt{DISCOUNT} & \texttt{TAX}\\ 
        \hline
        \hline
        Original & 302 ms & 385 ms & 312 ms & 369 ms \\
        Compressed & 6975 ms & 7233 ms & 7189 ms & 7223 ms \\
        \fn{GetDoubleArray} & 18 ms & 8 ms & 19 ms & 18 ms \\
    \end{tabularx}
    \caption{Source measure lookup for \texttt{QUANTITY} \texttt{EXTENDEDPRICE}, \texttt{DISCOUNT}, and \texttt{TAX} for SF0.1.} 
    \label{tab:operations-sml}
\end{table}

In Table \ref{tab:operations-sml} that source measure lookup is reduced by more than one order of magnitude from the original implementation, and more than two orders of magnitude from the compressed implementation. The operation on the \texttt{EXTENDEDPRICE} column is faster than the others, because this can be done by simply passing the array pointer. The others are dictionary encoded, takes longer, but is still fast. The fact that values from \texttt{QUANTITY} have to be converted from integer to floating points does not affect the result.

\subsection{Lookup Index Generation}
\label{sub:Lookup Index Generation}

\begin{table}
    \centering
    \begin{tabularx}{\textwidth}{X | X X X}
        & \texttt{LINESTATUS} & \texttt{RETURNFLAG} & \texttt{SHIPDATE}\\ 
        \hline
        \hline
        Original & 2939 ms & 2849 ms & 13144 ms \\
        Compressed & 12,291 ms & 12,688 ms & 19,674 ms \\
        \fn{GetLookupIndex} & 26 ms & 26 ms & 220 ms \\
    \end{tabularx}
    \caption{Lookup index generation operation for SF0.1 in Benchmark \ref{bm:q1}}
    \label{tab:operations-lig}
\end{table}
The \fn{GetLookupIndex} operation decreases the time it takes to performa join operation by two orders of magnitude, as seen in Table \ref{tab:operations-lig}.


\subsection{Identifier Index}
\label{sub:Identifier Index}
To test the performance of identifier index generation, Benchmark \ref{bm:odin-load} was used. In this benchmark, joins are not limited to small join columns, there is a join in that benchmark that joins 200,000 rows. Hence, the effects of creating the \fn{GetIdentifierIndex} operation are easier to measure.

\begin{table}
    \centering
    \begin{tabularx}{\textwidth}{X | X X}
        & \texttt{Fund} & \texttt{Customer} \\
        \hline
        \hline
        Compressed & 11 ms & 10,040 ms \\
        \fn{GetIdentifierIndex} & 9 ms & 2863 ms \\
    \end{tabularx}
    \caption{Lookup index generation for Benchmark \ref{bm:odin-load} with the new \fn{GetIdentifierIndex} operation.}
    \label{tab:operations-odin-lig}
\end{table}
As we see in Table \ref{tab:operations-odin-lig}, the time it takes to join \texttt{Customer Balance Daily} with \texttt{Customer} has been reduced by almost four times. Fund lookup performance is slightly improved. 

\subsection{Predicate Evaluation}
\label{sub:Predicate Evaluation}
\begin{table}
    \centering
    \begin{tabularx}{\textwidth}{X | X X X}
        Predicate & Original & Compressed & Predicate Operator \\
        \hline
        \hline
        \texttt{LINESTATUS = F} & 10,540 ms & 19,115 ms & 14,776 ms\\
        \texttt{TAX >= 0.02} & 9102 ms & 17,538 ms & 16,387 ms \\
        \texttt{EXTENDEDPRICE >= 1000} & 12,306 ms & 26,031 ms & 26,249 ms \\
        \texttt{EXTENDEDPRICE >= 40000} & 6946 ms & 13,682 ms & 11,475 ms \\
        \texttt{EXTENDEDPRICE < 1000} & 3535 ms & 4455 ms & 811 ms \\
        \texttt{EXTENDEDPRICE = 42995.94} & 53,291 ms & 55,291 ms & 29 ms \\
        \texttt{SHIPDATE IN 1995} & 13,286 ms & 17,748 ms & 5591 ms \\
        \texttt{SHIPINSTRUCT\_NULL HAS VALUE} & 7853 ms & 19,656 ms & 19,107 ms 
    \end{tabularx}
    \caption{Test results for Benchmark \ref{bm:filter} for originaland compressed column implementation, with and without predicate evaluation operators.}
    \label{tab:operations-filter}
\end{table}
To test predicate evaluation, we use the \textit{Filter Benchmark}, Benchmark \ref{bm:filter}. This moves data from one datasource to another based on a filter. The results are presented in Table \ref{tab:operations-filter}.

For all high-selectivity predicate evaluations, using the new predicate operator function in the columns increase performance, but is slower than the original implementation. Low selectivity predicates, like \texttt{EXTENDEDPRICE < 10000} (44) and \texttt{EXTENDEDPRICE = 42995.94} (1) are faster than the original implementation, with the latter three orders of magnitude faster.

\section{Discussion}
\label{sec:Discussion}
We are excited to see the benefits of introducing column operations. Both lookup index and measure lookup operations used by \gd~have increased performance by one or two orders of magnitude as an effect of utilizing the storage format, avoiding memory allocations, and layers of indirection. Another operation, \fn{GetLookupIndex} has also speeded up joining of two equally sized columns by almost four times. This operation is also used other places in \gap.

Although predicate evaluation operators have speeded up the operation where objects are moved from one data source to another based on a filter operation, most of them are still slower than the original implementation. The reason for this is that \gap~is not designed to utilize the new storage format; to move data from one datasource to another, rows, or \cn{CompositionFieldValueCollection} are created, filled with \cn{GValues} and transfered. Still, the full potential of predicate evaluation operators as a column operator revealed itself in \texttt{EXTENDEDPRICE = 42995.94}: The operation speeded up with three orders of magnitude.

\section{Chapter Conclusion}
\label{sec:Chapter Conclusion}
We conclude that there are much to gain from utilizing the column structure. In this chapter, we defined four column operations, all of which has a potential to increase performance by one, two, and even three orders of magnitude. Common for these operations is that they work on all values for an object class property consecutively, which is key to acheive good performance. All operations that took longer due to our new, compressed storage format, are now faster than the original implementation.

\subsection{Future Work}
\label{sub:Future Work}
Generally speaking, future work should aim to identify more column operators that can increase performance in \gap. As we have seen so far in this report, the compressed column format has normally decreased performance for operations that reads values intensively. This is normally caused by the \cn{GValue} interface with the data, which means values are allocated on the heap on each data access. However, most such operation benefits from having data stored as primitive data types in columns, or as dictionary columns. The job is to find such operations and implement them in the \fn{FieldValueCollection} class.

The predicate evaluation operator can speed up low-selectivity filters with three orders of magnitude. However, for high-selectivity filters, the overhead with moving data from one data source to another is large. Future work should seek to reduce this overhead by exploiting the column storage, for instance by creating an operation that moves all data from one column store to another based on a bitmap. This way, all filters can be applied on the original data source, combined using \texttt{AND} and \texttt{OR} operations, then be used as an input for this copy operation.
