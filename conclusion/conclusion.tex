\chapter{Conclusion}
\label{chap:Conclusion}

This chapter concludes this research and points at interesting directions for future work.

\clearpage

\section{Conclusion}
\label{sec:Conclusion}

In this research, we set out to answer the following research question:

\setlength{\leftskip}{1cm}

\textbf{RQ1: How can technology used by in-memory, read-optimized databases improve \gap's ability to handle and analyze large datasets, and what can model-driven engineering, in general, learn from database technology?}

\setlength{\leftskip}{0pt}

We conclude that techniques used in read-optimized, in-memory databases have improved \gap's ability to handle and analyze large amounts of data. First, column storage with primitive data types, dictionary encoding, bitpacking, and null pointer compression significantly reduce memory consumption. In the \tpchdl, the number of bytes needed per \lineitem~has been lowered by 67 \%. Second, load time has improved by 36 \%. Regarding performance, we see that \gap~benefits from the same principles as OLAP databases: By avoiding branches and improving cache locality, CPU throughput is maximized, and join, lookup, and filter operations are one, two, and even three orders of magnitude faster than the original implementation. Write performance is not slowed down as a result of the new internal data representation, although certain read-intense operations which are not adapted to the new structures are.

Our research has, by using the modifications in \gap~as a proof-of-concept, introduced evidence that \mde~benefits from database technology. Due to the wide variety of approaches used by \mdd~tools, we cannot draw any general conclusions whether the exact techniques we applied to \gap~can be employed by all \mde~supporting infrastructures, but we have shown the importance of internal data representation. Thus, \mde~tools which need support for analysis of large datasets, like \bd~functionality, should look at the database technology for inspiration. 

All of our changes lie in the method engineering layer. The tool optimizes internal data structure without affecting modelers in the information system layer. Hence, expert users can continue to focus on the business problem, and not worry about the underlying implementation. We pointed out that similar techniques can be applied to traditional object-oriented languages, where the problem is that classes serve the role as both business abstractions and data containers.

\section{Future work}
\label{sec:Future work}
In this research, we have only implemented and discovered a few methods used by read-optimized, in-memory databases. Future work should aim to identify more techniques that can be used in the context of \mde, also methods used in OLTP. Such techniques include parallelism and scaling, delta stores, indexes, result caching, code generation, query optimization, and more. Database technology has been a major research field for decades, so there should be plenty of techniques that can be applied to \mdd~supporting infrastructures.

In Section \ref{sec:Column Selection}, we saw how \gap~decides whether to apply dictionary encoding to a column or not by using database statistics and in Section \ref{sub:Implications for Model-Driven Engineering} we claimed that data should be represented in the best-suited format for different application tasks. Future work should pursue this topic. \mde~has a major advantage over general-purpose databases: \mdd~tools has extensive knowledge of data interpretation, and how and when the data is used. Hence, this knowledge, combined with database statistics, should be exploited to make intelligent decisions on which storage format that should be used for different parts of the application.

Last, but not least, this research has focused on what \mde~can learn from database technology. What if we turn the problem around and ask ourselves: What can database technology learn from \mde? Future work should investigate if techniques, terminology, and technology well known in \mde~applies to databases as well. For instance, could databases benefit from having an extra layer of data interpretation on top of data types? Should database schemas contain not only data type definitions and relations, but also information on how and when the data is used?

\subsection{Genus App Platform}
\label{sub:Genus App Platform}
Above we discussed general topics for future work. However, the research has resulted in an extensive list of ideas specific for \gap~which we enumerate in this section. Some of the ideas are fetched from Chapters 5-9, while others are new.

\subsubsection{Genus Discovery Specific Optimizations}
\label{ssub:Genus Discovery Specific Optimizations}
The original motivation for this research was to improve analytic capabilities in \gap~by studying how the \bd~functionality in the platform could be improved. However, we have only implicitly improved \gd~by reducing memory usage and load time. \gd~still works on arrays of floating points exclusively and does not exploit the data structures implemented in this research. Future work should improve and modify \gd~to work such that it can operate on dictionary encoded columns directly, and also apply state-of-the-art techniques for joining, grouping, and aggregation.

\subsubsection{Horizontal Partitioning and Delta Store}
\label{ssub:Horizontal Partitioning and Delta Store}
In Chapter \ref{chap:column-store} and Chapter \ref{chap:storage-format}, we briefly discussed horizontal partitioning. Future work should investigate the effects of horizontal partitioning in \gap. \cn{CompositionObject} and \cn{CompositionValueCollection} could be extended with a partition index. This way \gap~could leverage all benefits of this technique, which is metadata pruning, parallelization, and better support for data skew. At the same time, the effects of a delta store could be investigated: Newly created partitions could be optimized for data inserts and updates, while full partitions could be stored in read-optimized, immutable structures.

\subsubsection{Dynamic Storage Formats}
\label{ssub:Dynamic Storage Formats}
In the current implementation, \gap~tries to make a qualified decision whether to apply dictionary encoding to a column or not. However, as we saw in Chapter \ref{chap:compression}, dictionary encoded columns takes a longer time to load. Hence, it might be beneficial to load all data into non-compressed columns first, and only then make a decision whether data should be rebuilt as a dictionary encoded column. Then the restructure operation could happen in a separate, low-priority thread. Future work should investigate the effects of such dynamic storage formats. \gap~should also try to deallocate data in data sources that are no longer in use. For instance, the entire column can be dropped after a floating point array is extracted in the source measure lookup operation.

\subsubsection{Server State}
\label{ssub:Server State}
An important principle in \gap, is the \textit{stateless} application backed, \textit{Genus App Services}. Although this has several benefits regarding simplicity and scalability, it has certain disadvantages. One disadvantage, is that clients talk with the database infrastructure directly, mostly using XML, which \gap~compress the data after it has traversed the network. Ideally, the compression should happen in the database infrastructure, or in \textit{Genus App Services}. Hence, future work should investigate the effects of applying state to the server. Not only would server state reduce network traffic, but it would also improve client load time if the data is already structured as columns. This could also relax memory requirement for clients as more data processing and aggregations can be performed on the server.
