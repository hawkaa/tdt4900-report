{\Huge Abstract}
\vspace{1cm}
% Field of research
% A brief motivation for the work
% What the research topic is
% Research approach(es) applied
% contributions

Research has recently shown a keen interest in database technology for analytical workloads that enables high-performance analysis and on-the-fly aggregation recently, where the main motivation is \bi~products. Such products store data in main memory as compressed columns to maximize memory utilization and CPU throughput. \mde, a discipline that aims to increase developer productivity through the use of models on a higher level of abstraction, automates many of the complex programming tasks, like persistence and interoperability. One such product, \gap, has evolved over time and become a powerful and expressive tool for rapid application development. However, operations that process large amounts of data are slow, and the platform has a high memory footprint, mainly because no particular attention has been paid to storage format and structures in the source code. Based on the observation that \gap~has many similarities with an in-memory database, we are motivated to investigate if \gap~and \mdd~can benefit from database technology for analytical workloads. \todo{Adjust background info on databases to align with the introduction (non-BI focus, only in-memory)?}

In this research, we enhance data representation, implement column storage with dictionary encoding and bitpacking in \gap~to reduce memory footprint and increase the platform ability to handle large datasets. We identify operations that can exploit the new storage format, like join and filter operations, and provide a discussion of which storage format that should be used in different parts of the platform. We test our implementation using a standard benchmark for analytical workloads, the \tpch~while monitoring write performance and make sure it is not significantly affected.

Column storage with dictionary encoding, bitpacking, and null-pointer compression leads to a memory reduction of 67 \% and a load time reduction of 34 \%. Also, operations that are adjusted to utilize the column storage format sees a performance impact of one, two, or sometimes three orders of magnitude compared to the original implementation. None of these changes affect write performance significantly. We have thus proved the potential of applying database technology to \mde.

%Column storage alone has lead to a memory reduction of about 70\% in certain test cases. In addition to this, several operations have had performance improvements of 100X-1000X, including filter operations and index generation. We have been able to isolate a small set of operations that can be used as tools for efficient programs. We have proved that database technology can be used in a model-driven development tool, something that has not been done before.

% With the advent of Big Data and \bd~products, database technology for high-performance analysis of data has become increasingly more popular. Data is commonly stored as columns for easy aggregation of data, better compression, and better CPU and cache performance. \mdd~has been around for decades, but has not gained particular traction until now. \gap~is one such platform. This system has evolved for roughly twenty years into becoming a powerful tool for rapid application development. Although most of the data in \gap~are persisted in relational databases (like \oracle, \mssql, \mysql), the data processing happens in-memory. No particular attention has been paid to storage formats and structures, data has been stored in whichever structures that are the most convenient for the developes of \gap. This research investigates which technologies from the research field of databases that can be applied to the field of \mdd, and which techniques from \mdd that are promising for the data field.
